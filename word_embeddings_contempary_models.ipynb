{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_embeddings_contempary_models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPxZfSFv75Hn+YPJcJUYfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewpkitchin/Word-Embeddings/blob/master/word_embeddings_contempary_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1lZwGGeuGRM",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we will demonstrate how to use the contempary word embedding models supported by the Gensim library. We will calculate the individual cosine of each enitity and moral standing words as well as the cosine between each enitity and a group/average vector of the moarl standing words.\n",
        "\n",
        "**Key tips**\n",
        "\n",
        "We suggest mounting a google drive to output the csv files of cosines for each model. See https://github.com/RaRe-Technologies/gensim-data for a list of models and documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL7MV22Ht3Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dependancies\n",
        "\n",
        "from google.colab import drive\n",
        "import csv, time\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRUnXwTX1XG-",
        "colab_type": "text"
      },
      "source": [
        "We first mount our google drive and navigate to our desired folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk4vc1lZv1ek",
        "colab_type": "code",
        "outputId": "31e25cdd-26d9-449d-a2bc-2e77d4de6e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My\\ Drive/word2vecProject/csvFiles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/word2vecProject/csvFiles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7x7QZH1MGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_models = ['word2vec-google-news-300']\n",
        "\n",
        "#'glove-twitter-100', 'glove-twitter-200', 'glove-twitter-25', 'glove-twitter-50', \n",
        "#'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-wiki-gigaword-50',\n",
        "#'fasttext-wiki-news-subwords-300'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX1ivGzt2WNd",
        "colab_type": "text"
      },
      "source": [
        "Here we create a function which returns the normalized vector representation of a word from a model. Note: word_vector will be defined as follows:\n",
        "\n",
        "word_vector = api.load(model_name)\n",
        "\n",
        "we will define this when we load and run the models.\n",
        "\n",
        "We also create a function to compute the cosine of two vectors as well as a function to compute the average vector of a list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNqEAq_C0oAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(word):\n",
        "  return word_vector[word]/np.linalg.norm(word_vector[word])\n",
        " \n",
        "\n",
        "def cosine_similarity(vec1,vec2):\n",
        "  return np.dot(vec1, vec2)/(np.linalg.norm(vec1)* np.linalg.norm(vec2))\n",
        "\n",
        "\n",
        "def average_vector(listOfWords, average_vec):\n",
        "  for word in listOfWords:\n",
        "    try:\n",
        "      average_vec += norm(word)\n",
        "    except KeyError:\n",
        "      continue\n",
        "  \n",
        "  return average_vec/(len(listOfWords)+1)\n",
        "\n",
        "\n",
        "def relativeNormDifference(groupVec1, groupVec2, word):\n",
        "  return np.linalg.norm(word - groupVec1)-np.linalg.norm(word - groupVec2)\n",
        "\n",
        "#  output = 0\n",
        "#  for word in listOfWords:\n",
        "#    output += np.linalg.norm(word - groupVec1)-np.linalg.norm(word - groupVec2)\n",
        "#  return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWPJZkkmWV_a",
        "colab_type": "text"
      },
      "source": [
        "Here we define three functions. The first cycles through our list of words and compute the cosine similarity between each pair. The second function is for the average vector approach. The third is using a relative norm difference apporach similar to that of PNAS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7WTcc_n-4bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosines_to_csv(csv_name, list1, list2, model_name):\n",
        "  with open(csv_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    list2.insert(0,model_name)\n",
        "\n",
        "    # Write the headings to the csv.\n",
        "    writer.writerow(list2)\n",
        "\n",
        "    list2.pop(0)\n",
        "\n",
        "    for word in list1:\n",
        "      listOfCosines = []\n",
        "      listOfCosines.append(word)\n",
        "      \n",
        "      for entity in list2:\n",
        "        try:\n",
        "          listOfCosines.append(cosine_similarity(norm(word),norm(entity)))\n",
        "        except KeyError:\n",
        "          listOfCosines.append('NA')\n",
        "\n",
        "      # Writing the cosine scores to the csv.\n",
        "      writer.writerow(listOfCosines)\n",
        "\n",
        "\n",
        "def average_vector_cosines_to_csv(csv_name,average_vec,list2, model_name):\n",
        "  with open(csv_name, 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    listOfCosines = []\n",
        "    listOfCosines.insert(0,model_name)\n",
        "\n",
        "    for word in list2:\n",
        "      try:\n",
        "        listOfCosines.append(cosine_similarity(average_vec,norm(word)))\n",
        "      except KeyError:\n",
        "        listOfCosines.append('NA')\n",
        "      \n",
        "    # Writing the cosine scores to the csv.\n",
        "    writer.writerow(listOfCosines)\n",
        "\n",
        "\n",
        "def relative_norm_difference_to_csv(csv_name, average_vec1, average_vec2, list2, model_name):\n",
        "  with open(csv_name, 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    listOfCosines = []\n",
        "    listOfCosines.insert(0,model_name)\n",
        "\n",
        "    for word in list2:\n",
        "      try:\n",
        "        listOfCosines.append(relativeNormDifference(average_vec1, average_vec2, norm(word)))\n",
        "      except KeyError:\n",
        "        listOfCosines.append('NA')\n",
        "      \n",
        "    # Writing the cosine scores to the csv.\n",
        "    writer.writerow(listOfCosines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS9VPaVpNMX_",
        "colab_type": "text"
      },
      "source": [
        "Lists of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THkaQpjelLcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moral_standing = ['care', 'cares', 'cared', 'caring', 'help', 'helps', 'helping', 'helped', 'donate', 'donates', 'donating', 'donated', 'aid', 'aiding', 'aided',  'empathy', 'empathetic', 'empathizing', 'empathizes', 'sympathy', 'sympathetic', 'sympathizing', 'sympathizes', 'compassion', 'compassionate']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sJ7iWRKlbSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entities = ['husband','wife','father','mother','son','daughter','brother','sister','uncle','aunt','niece','nephew','cousin','grandmother','grandfather','acquaintance','ally','associate','colleague','comrade','counterpart','fellow','neighbour','patriot','confidant','friend','companion','partner','supporter','member','follower','emigrant','foreigner','intruder','settler','stranger','visitor','vagrant','opposition','rival','opponent','adversary','competitor','invader','trespasser','interloper','occupier','arab','beggar','blacks','crippled','disabled','jew','mexican','unemployed','vagabond','addict','native','elderly','indian','woman','chinese','pauper','enemy','villain','crook','delinquent','murderer','robber','thief','deserter','traitor','liar','convict','criminal','felon','offender','pickpocket','scoundrel','animal','ape','bird','elephant','chicken','cow','dog','fish','pig','shark','bear','snake','cat','fox','monkey','horse','lion',\t'nature','forest','lake','mountain','ocean','reef','river','tree','sea','beach','island','air','water','coast','jungle','earth','planet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wf7c59eD_9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moral_standing_positive = ['care', 'cares', 'cared', 'caring', 'help', 'helps', 'helping', 'helped', 'aid', 'aiding', 'aided']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HtRwxOnEIWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moral_standing_negative = ['harm', 'kill', 'kills', 'killing', 'killed', 'annihilate', 'annihilates', 'annihilated', 'exterminate', 'exterminated']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMkZ8oTFM2ja",
        "colab_type": "text"
      },
      "source": [
        "Average vector approach "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUwKeJ_B2WD0",
        "colab_type": "code",
        "outputId": "01ff7bbd-21ec-4e21-e8c3-2549c2bd330d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "with open('cosines_enitities_and_moral_standings_average_vec_contempary.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    \n",
        "    entities.insert(0,\" \")\n",
        "    writer.writerow(entities)\n",
        "    entities.pop(0)\n",
        "\n",
        "\n",
        "for i in list_of_models:\n",
        "  word_vector = api.load(i)\n",
        "  \n",
        "  j = word_vector['word'].shape[0]\n",
        "  \n",
        "  average_vec = np.zeros([j, ])\n",
        "\n",
        "  moral_standings_aver_vec = average_vector(moral_standing_positive, average_vec)\n",
        "\n",
        "  average_vector_cosines_to_csv('cosines_enitities_and_moral_standings_average_vec_contempary.csv', moral_standings_aver_vec, entities, i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 98.3% 380.7/387.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[================================------------------] 64.1% 486.5/758.5MB downloadedBuffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgR4oZO7NEJ_",
        "colab_type": "text"
      },
      "source": [
        "Individual appraoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lblApKjSty70",
        "colab_type": "code",
        "outputId": "6d81fbde-c6c5-4220-c4be-db69b72bc71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "for i in list_of_models:\n",
        "  word_vector = api.load(i)\n",
        "\n",
        "  cosines_to_csv('cosines_enitities_and_moral_standings_{}.csv'.format(i), moral_standing, entities, i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.5% 1653.9/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C95IARNoVGl9",
        "colab_type": "text"
      },
      "source": [
        "Relative norm difference approach "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynRT3l1wVQQu",
        "colab_type": "code",
        "outputId": "9565f9ff-ee73-4153-a72a-ecbd8de3828e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "with open('rnd_enitities_and_moral_standings_contempary.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    \n",
        "    entities.insert(0,\" \")\n",
        "    writer.writerow(entities)\n",
        "    entities.pop(0)\n",
        "\n",
        "for i in list_of_models:\n",
        "  word_vector = api.load(i)\n",
        "\n",
        "  j = word_vector['word'].shape[0]\n",
        "  \n",
        "  average_vec = np.zeros([j, ])\n",
        "\n",
        "  positive_aver_vec = average_vector(moral_standing_positive, average_vec)\n",
        "\n",
        "  average_vec = np.zeros([j, ])\n",
        "\n",
        "  negative_aver_vec = average_vector(moral_standing_negative, average_vec)\n",
        "\n",
        "  relative_norm_difference_to_csv('rnd_enitities_and_moral_standings_contempary.csv', positive_aver_vec, negative_aver_vec, entities, i)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.6% 385.7/387.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n",
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "[=================================================-] 99.8% 956.5/958.4MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBmetr7ozar_",
        "colab_type": "text"
      },
      "source": [
        "Archived"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA_Fz517pxy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_words_to_remove = []\n",
        "\n",
        "for i in list_of_models:\n",
        "  list_of_words_to_remove.append(i)\n",
        "  word_vector = api.load(i)\n",
        "  list_of_words_to_remove.append('ENTITIES')\n",
        "  for enitity in entities:\n",
        "    try: \n",
        "      word_vector[enitity]\n",
        "    except KeyError:\n",
        "      list_of_words_to_remove.append(enitity)\n",
        "  list_of_words_to_remove.append('MORALS')\n",
        "  for moral in moral_standing:\n",
        "    try: \n",
        "      word_vector[moral]\n",
        "    except KeyError:\n",
        "      list_of_words_to_remove.append(moral)\n",
        "  print(list_of_words_to_remove)\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}