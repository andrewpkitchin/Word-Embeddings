{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "study_one_calculating_cosines_contempary_models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCRr5qY1QaFNC0OoP1vmoI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewpkitchin/moral-concern-word-embeddings/blob/master/study_one_calculating_cosines_contempary_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJTMIpWzZjMN"
      },
      "source": [
        "In this Python 3 notebook, we will demonstrate how to use contempary word embedding models supported by the Gensim library to generate the results used in [link to paper]. We will calculate the cosine between each focal enitity and each moral concern word.\n",
        "\n",
        "See https://github.com/RaRe-Technologies/gensim-data for a list of models and documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZDx2Cx4Zd97"
      },
      "source": [
        "# Dependancies\n",
        "\n",
        "import csv, numpy as np, gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh4VuYvwZibg"
      },
      "source": [
        "# List of contempary models we have used. Information on these can be found at https://github.com/RaRe-Technologies/gensim-data\n",
        "\n",
        "list_of_models = ['word2vec-google-news-300']\n",
        "\n",
        "#Google News Model\n",
        "  #'word2vec-google-news-300'\n",
        "#Twitter Models\n",
        "  #'glove-twitter-100', 'glove-twitter-200', 'glove-twitter-25', 'glove-twitter-50', \n",
        "#Wikipedia Models\n",
        "  #'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-wiki-gigaword-50',\n",
        "  #'fasttext-wiki-news-subwords-300'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqHQbFFXZoy-"
      },
      "source": [
        "Here we create a function which returns the normalized vector representation of a word from a model. Note: word_vector will be defined as follows:\n",
        "\n",
        "word_vector = api.load(model_name)\n",
        "\n",
        "we will define this when we load and run the models. We also create a function to compute the cosine similarity of each pair of words from two input lists."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glnLC2KHZsox"
      },
      "source": [
        "def norm(word):\n",
        "  return word_vector[word]/np.linalg.norm(word_vector[word])\n",
        " \n",
        "def cosine_similarity(vec1,vec2):\n",
        "  return np.dot(vec1, vec2)/(np.linalg.norm(vec1)* np.linalg.norm(vec2))\n",
        "\n",
        "def average_vector(list_of_words, average_vec):\n",
        "  for word in list_of_words:\n",
        "    try:\n",
        "      average_vec += norm(word)\n",
        "    except KeyError:\n",
        "      continue\n",
        "  \n",
        "  return average_vec/(len(list_of_words)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXdbH1z8ZvOV"
      },
      "source": [
        "def cosines_to_csv(csv_name, list1, list2, model_name):\n",
        "  with open(csv_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    list2.insert(0,model_name)\n",
        "\n",
        "    # Write the headings to the csv.\n",
        "    writer.writerow(list2)\n",
        "\n",
        "    list2.pop(0)\n",
        "\n",
        "    for word in list1:\n",
        "      listOfCosines = []\n",
        "      listOfCosines.append(word)\n",
        "      \n",
        "      for entity in list2:\n",
        "        try:\n",
        "          listOfCosines.append(cosine_similarity(norm(word),norm(entity)))\n",
        "        except KeyError:\n",
        "          listOfCosines.append('NA')\n",
        "\n",
        "      # Writing the cosine scores to the csv.\n",
        "      writer.writerow(listOfCosines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvm6GAl7ZyBU"
      },
      "source": [
        "moral_concern_list = ['care', 'cares', 'caring', 'cared', 'concern', 'concerns', 'concerned', 'concerning', 'empathy', 'empathetic', 'empathize', 'sympathy', 'sympathize', 'sympathetic', 'compassion', 'compassionate', 'uncaring', 'apathetic', 'apathy', 'unconcerned', 'unconcerning', 'indifference', 'indifferent', 'unsympathetic', 'unempathetic', 'uncompassionate', 'disregard', 'disregarded', 'disregarding']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfkYwYN7ZzfV"
      },
      "source": [
        "entities_list = ['husband', 'wife', 'father', 'mother', 'son', 'daughter', 'brother', 'sister', 'uncle', 'aunt', 'niece', 'nephew', 'grandmother', 'grandfather', 'acquaintance', 'ally', 'associate', 'colleague', 'counterpart', 'fellow', 'neighbor', 'patriot', 'confidant', 'companion', 'partner', 'supporter', 'member', 'follower', 'emigrant', 'foreigner', 'intruder', 'settler', 'stranger', 'visitor', 'vagrant', 'opposition', 'rival', 'opponent', 'adversary', 'competitor', 'invader', 'occupier', 'arab', 'beggar', 'blacks', 'crippled', 'disabled', 'jew', 'mexican', 'unemployed', 'native', 'elderly', 'indian', 'woman', 'chinese', 'pauper', 'animal', 'ape', 'bird', 'elephant', 'chicken', 'cow', 'dog', 'fish', 'pig', 'shark', 'bear', 'snake', 'monkey', 'lion', 'nature', 'forest', 'lake', 'mountain', 'ocean', 'reef', 'river', 'tree', 'sea', 'beach', 'island', 'coast', 'earth', 'planet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT6WiSY0Z6c8"
      },
      "source": [
        "\n",
        "Computing the cosine similarity between each entity word and each moral concern word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKzTgy9FZ2-D"
      },
      "source": [
        "for i in list_of_models:\n",
        "  word_vector = api.load(i)\n",
        "  cosines_to_csv('entities_and_moral_concern_cosines_{}.csv'.format(i), moral_concern_list, entities_list, i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}