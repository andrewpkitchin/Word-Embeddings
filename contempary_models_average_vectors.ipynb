{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "contempary_models_average_vectors.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXiiFVLornKlsHQjB4ONWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewpkitchin/moral-circle-word-embeddings/blob/master/contempary_models_average_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1lZwGGeuGRM",
        "colab_type": "text"
      },
      "source": [
        "In this Python 3 notebook we will demonstrate how to use contempary word embedding models supported by the Gensim library to generate the results used in [link to paper]. We will calculate the cosine between each focal enitity and the average vector of the moarl words.\n",
        "\n",
        "We suggest mounting a Google Drive to output results as csv files of cosines for each model.\n",
        "\n",
        "See https://github.com/RaRe-Technologies/gensim-data for a list of models and documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL7MV22Ht3Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dependancies\n",
        "\n",
        "from google.colab import drive\n",
        "import csv, numpy as np, gensim.downloader as api\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk4vc1lZv1ek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7efdf9aa-4f0d-4157-db2e-115d4cfbfb66"
      },
      "source": [
        "# Mounting a Google Drive.\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/My\\ Drive/word2vecProject/csvFiles"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/word2vecProject/csvFiles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7x7QZH1MGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of contempary models we have used. Information on these can be found at https://github.com/RaRe-Technologies/gensim-data\n",
        "\n",
        "list_of_models = ['word2vec-google-news-300','glove-twitter-100', 'glove-twitter-200', 'glove-twitter-25', 'glove-twitter-50','glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-wiki-gigaword-50','fasttext-wiki-news-subwords-300']\n",
        "\n",
        "#Google News Model\n",
        "  #'word2vec-google-news-300'\n",
        "#Twitter Models\n",
        "  #'glove-twitter-100', 'glove-twitter-200', 'glove-twitter-25', 'glove-twitter-50', \n",
        "#Wikipedia Models\n",
        "  #'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-wiki-gigaword-50',\n",
        "  #'fasttext-wiki-news-subwords-300'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX1ivGzt2WNd",
        "colab_type": "text"
      },
      "source": [
        "Here we create a function which returns the normalized vector representation of a word from a model. Note: word_vector will be defined as follows:\n",
        "\n",
        "> word_vector = api.load(model_name)\n",
        "\n",
        "we will define this when we load and run the models. We also create a function to compute the cosine similarity of two vectors as well as a function to compute the average vector of a list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNqEAq_C0oAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(word):\n",
        "  return word_vector[word]/np.linalg.norm(word_vector[word])\n",
        " \n",
        "\n",
        "def cosine_similarity(vec1,vec2):\n",
        "  return np.dot(vec1, vec2)/(np.linalg.norm(vec1)* np.linalg.norm(vec2))\n",
        "\n",
        "\n",
        "def average_vector(list_of_words, average_vec):\n",
        "  for word in list_of_words:\n",
        "    try:\n",
        "      average_vec += norm(word)\n",
        "    except KeyError:\n",
        "      continue\n",
        "  \n",
        "  return average_vec/(len(list_of_words)+1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWPJZkkmWV_a",
        "colab_type": "text"
      },
      "source": [
        "Here we define a function for computing the cosine similarity between words in a list and the group/average vector of a list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7WTcc_n-4bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_vector_cosines_to_csv(csv_name, average_vec, list_of_words, model_name):\n",
        "  with open(csv_name, 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    list_of_cosines = []\n",
        "    list_of_cosines.insert(0,model_name)\n",
        "\n",
        "    for word in list_of_words:\n",
        "      try:\n",
        "        list_of_cosines.append(cosine_similarity(average_vec,norm(word)))\n",
        "      except KeyError:\n",
        "        list_of_cosines.append('NA')\n",
        "      \n",
        "    # Writing the cosine scores to the csv.\n",
        "    writer.writerow(list_of_cosines)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS9VPaVpNMX_",
        "colab_type": "text"
      },
      "source": [
        "Lists of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPY60fBUMuyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moral_list = ['compassion', 'compassionate','care', 'cares', 'cared', 'caring','help', 'helps', 'helped', 'helping','responsibility', 'responsibilities','duty', 'duties','concern', 'concerns', 'concerned', 'concerning','welfare','rights','support', 'supports', 'supporting', 'supported','assist', 'assists', 'assisting', 'assisted']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sJ7iWRKlbSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focal_entities_list = ['husband', 'wife', 'father', 'mother', 'son', 'daughter', 'brother', 'sister', 'uncle', 'aunt', 'niece', 'nephew', 'grandmother', 'grandfather', 'acquaintance', 'ally', 'associate', 'colleague', 'confidant', 'companion', 'counterpart', 'fellow', 'follower', 'member', 'neighbor', 'partner', 'patriot', 'supporter', \n",
        "'arab', 'beggar', 'blacks', 'chinese', 'crippled', 'disabled', 'elderly', 'indian', 'jew', 'mexican', 'native', 'pauper', 'unemployed', 'woman', 'adversary', 'competitor', 'emigrant', 'foreigner', 'intruder', 'invader', 'occupier', 'opponent', 'opposition', 'rival', 'settler', 'stranger', 'visitor', 'vagrant', \n",
        "'convict', 'criminal', 'crook', 'delinquent', 'deserter', 'enemy', 'felon', 'murderer', 'offender', 'robber', 'scoundrel', 'thief', 'traitor', 'villain', 'animal', 'ape', 'bear', 'bird', 'chicken', 'cow', 'dog', 'elephant', 'fish', 'lion', 'monkey', 'pig', 'shark', 'snake', 'beach', 'coast', 'earth', 'forest', 'island', \n",
        "'lake', 'mountain', 'nature', 'ocean', 'planet', 'reef', 'river', 'sea', 'tree']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMkZ8oTFM2ja",
        "colab_type": "text"
      },
      "source": [
        "Computing the cosine similarity between each focal entity and the average vector of the moral words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUwKeJ_B2WD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "0fd07dce-580d-4325-c2b5-dc2fe5972669"
      },
      "source": [
        "with open('focal_entities_and_moral_average_vec_contempary.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    \n",
        "    focal_entities_list.insert(0,\" \")\n",
        "    writer.writerow(focal_entities_list)\n",
        "    focal_entities_list.pop(0)\n",
        "\n",
        "\n",
        "for i in list_of_models:\n",
        "  word_vector = api.load(i)\n",
        "  \n",
        "  j = word_vector['word'].shape[0]\n",
        "  \n",
        "  average_vec = np.zeros([j, ])\n",
        "\n",
        "  moral_list_aver_vec = average_vector(moral_list, average_vec)\n",
        "\n",
        "  average_vector_cosines_to_csv('focal_entities_and_moral_average_vec_contempary.csv', moral_list_aver_vec, focal_entities_list, i)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 98.4% 1635.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 98.1% 379.7/387.1MB downloaded\n",
            "[===============================================---] 94.1% 714.1/758.5MB downloaded\n",
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
            "[=================================================-] 99.4% 952.4/958.4MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}